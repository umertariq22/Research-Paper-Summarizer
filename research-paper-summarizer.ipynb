{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11592985,"sourceType":"datasetVersion","datasetId":7269689}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U datasets==2.20.0 huggingface_hub==0.23.4 transformers peft==0.11.1 bitsandbytes==0.43.2 matplotlib==3.9.0 scikit-learn==1.5.0 evaluate bert_score rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:17:40.645596Z","iopub.execute_input":"2025-05-07T09:17:40.645927Z","iopub.status.idle":"2025-05-07T09:19:27.495513Z","shell.execute_reply.started":"2025-05-07T09:17:40.645899Z","shell.execute_reply":"2025-05-07T09:19:27.494853Z"}},"outputs":[{"name":"stdout","text":"Collecting datasets==2.20.0\n  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\nCollecting huggingface_hub==0.23.4\n  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nCollecting peft==0.11.1\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes==0.43.2\n  Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting matplotlib==3.9.0\n  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting scikit-learn==1.5.0\n  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (19.0.1)\nCollecting pyarrow-hotfix (from datasets==2.20.0)\n  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.70.16)\nCollecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0)\n  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.11.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.4) (4.13.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (7.0.0)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (2.5.1+cu124)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (1.3.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (1.4.8)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (3.6.0)\nINFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting transformers\n  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\nINFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nCollecting tokenizers<0.21,>=0.20 (from transformers)\n  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.11.1)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.11.1) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets==2.20.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=94caca7f9be7ef37609cc1aa976239af26f678f201c54f403b2e831359fbfd99\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: pyarrow-hotfix, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, tokenizers, nvidia-cusolver-cu12, transformers, matplotlib, datasets, scikit-learn, rouge_score, peft, evaluate, bitsandbytes, bert_score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.30.2\n    Uninstalling huggingface-hub-0.30.2:\n      Successfully uninstalled huggingface-hub-0.30.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.5.0\n    Uninstalling datasets-3.5.0:\n      Successfully uninstalled datasets-3.5.0\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.5.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert_score-0.3.13 bitsandbytes-0.43.2 datasets-2.20.0 evaluate-0.4.3 fsspec-2024.5.0 huggingface_hub-0.23.4 matplotlib-3.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.11.1 pyarrow-hotfix-0.7 rouge_score-0.1.2 scikit-learn-1.5.0 tokenizers-0.20.3 transformers-4.46.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nfrom huggingface_hub import login\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\n\nfrom datasets import load_dataset\n\nfrom transformers import DataCollatorForLanguageModeling,DataCollatorForSeq2Seq, Trainer, AutoModelForCausalLM, RobertaTokenizerFast,AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, BitsAndBytesConfig\n\nfrom peft import PeftModel, PeftConfig, LoraConfig, get_peft_model, TaskType, replace_lora_weights_loftq, prepare_model_for_kbit_training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(\"All Imp Libraries has been Imported\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:26:41.997981Z","iopub.execute_input":"2025-05-07T09:26:41.998288Z","iopub.status.idle":"2025-05-07T09:26:42.004269Z","shell.execute_reply.started":"2025-05-07T09:26:41.998267Z","shell.execute_reply":"2025-05-07T09:26:42.003556Z"}},"outputs":[{"name":"stdout","text":"All Imp Libraries has been Imported\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\naccess_token = user_secrets.get_secret(\"access_token\")\nlogin_ = user_secrets.get_secret(\"login\")\ntogether_api_key = user_secrets.get_secret(\"together_api_key\")\n\nprint(\"Api Keys have been loaded\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:22:35.295366Z","iopub.execute_input":"2025-05-07T09:22:35.296018Z","iopub.status.idle":"2025-05-07T09:22:36.064736Z","shell.execute_reply.started":"2025-05-07T09:22:35.295994Z","shell.execute_reply":"2025-05-07T09:22:36.064005Z"}},"outputs":[{"name":"stdout","text":"Api Keys have been loaded\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"login(token=login_)\nprint(\"Login Successfull\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:22:38.671343Z","iopub.execute_input":"2025-05-07T09:22:38.671655Z","iopub.status.idle":"2025-05-07T09:22:38.890293Z","shell.execute_reply.started":"2025-05-07T09:22:38.671633Z","shell.execute_reply":"2025-05-07T09:22:38.889636Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nLogin Successfull\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"ccdv/arxiv-summarization\", \"section\")[\"train\"]\nds = ds.select(range(5000))\n\nprint(\"Dataset Loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:22:44.385142Z","iopub.execute_input":"2025-05-07T09:22:44.385418Z","iopub.status.idle":"2025-05-07T09:23:53.867777Z","shell.execute_reply.started":"2025-05-07T09:22:44.385397Z","shell.execute_reply":"2025-05-07T09:23:53.866967Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.96k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d69ba9286a41058b7cf820c084e7bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5deff6f388554b64aafd8d74f5e26cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/228M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a804bd83ad814e51a1491e49c944a093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/228M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a784dc323d48d78e75b6ca49f63eb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da454bf8406343ffa313b0cab0ed54e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/226M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a0f263839246f68a11e529886ae2da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf3d608783646b4a7ea6c9077bb036a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/229M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d02a591f5a1448078d91208ab4477f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0745b61c6b294e61832761c5ec054517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4f0ec3e0744d1495cd93635f89b030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/228M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424a7889e8c8457ebeb4054819c11792"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/229M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214b362ddd69428b97e6571ebebcb314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/231M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da38cfc739f40eb98ce9fe40831bf03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31cb5540e37147c3b819155d681ccf43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bb3140b1fc347e1bba217040ce61cff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/235M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ade66a3ea724d1e9bd78a06d2dfed4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/105M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4c9113d49547ed8ece7adb83aeff8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/105M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"180b3e52ae4447c1beeb5f2b5c11d658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/203037 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c84336f43b64cd8a2e7b42c56219f89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/6436 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"880b8a2e339a4d42a1242c0a7d0a5af0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/6440 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926f8601de374174a8ca59902f310045"}},"metadata":{}},{"name":"stdout","text":"Dataset Loaded\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\",\n                                          token=access_token)\ntokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize_function(examples):\n    model_inputs = tokenizer(\n        examples['article'],\n        max_length=1024,\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples['abstract'],\n            max_length=256,\n            padding=True,\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Apply tokenization\ntokenized_inp = ds.map(tokenize_function, batched=True)\n\nprint(\"Tokenization has been applied\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:31:56.649582Z","iopub.execute_input":"2025-05-07T09:31:56.649998Z","iopub.status.idle":"2025-05-07T09:32:47.993918Z","shell.execute_reply.started":"2025-05-07T09:31:56.649972Z","shell.execute_reply":"2025-05-07T09:32:47.993077Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62a2c1d453324a9cbbcc7b4d38bd6ef8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2cb5eac2c94b71a6c56e0ca332e6d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935f0ea9b57f495d9e701b98b1299ef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01223072cc7844c0b1ae55174d0b5103"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c17ca68a8ef4d76a261aca68c09fe00"}},"metadata":{}},{"name":"stdout","text":"Tokenization has been applied\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Spliting the Data","metadata":{}},{"cell_type":"code","source":"split_ds = tokenized_inp.train_test_split(test_size=0.2, seed=42)\n\nval_test_split = split_ds['test'].train_test_split(test_size=0.5, seed=42)\n\ntrain_dataset = split_ds['train']\nval_dataset = val_test_split['train']\ntest_dataset = val_test_split['test']\n\nprint(\"Dataset Splited\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:33:21.034015Z","iopub.execute_input":"2025-05-07T09:33:21.034284Z","iopub.status.idle":"2025-05-07T09:33:21.059614Z","shell.execute_reply.started":"2025-05-07T09:33:21.034260Z","shell.execute_reply":"2025-05-07T09:33:21.058930Z"}},"outputs":[{"name":"stdout","text":"Dataset Splited\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# LoRA-Based Fine-Tuning","metadata":{}},{"cell_type":"code","source":"# Load adapter config and base model from checkpoint\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",  # Normal float 4-bit\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=\"float16\"\n)\npeft_config = PeftConfig.from_pretrained(\"/kaggle/input/checkpoint/transformers/default/1/checkpoint-2000\")\nbase_model = AutoModelForCausalLM.from_pretrained(peft_config.base_model_name_or_path,\n                                                  quantization_config=bnb_config,\n                                                  device_map=\"auto\",\n                                                  token=access_token)\nbase_model = PeftModel.from_pretrained(base_model, \"/kaggle/input/checkpoint/transformers/default/1/checkpoint-2000\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:33:47.292926Z","iopub.execute_input":"2025-05-07T09:33:47.293670Z","iopub.status.idle":"2025-05-07T09:35:37.159371Z","shell.execute_reply.started":"2025-05-07T09:33:47.293636Z","shell.execute_reply":"2025-05-07T09:35:37.158691Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"676f069fa62149f7ade88be4723b5417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb39bff96af4b20b33caab63efb85b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdbdd100bc5f43afa6d1283d3306d3ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c72c71d9ff9f4fdea794e323118f7d84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3241f4a48bee43d7a3aa6c53fad20051"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d43293c24b634e39ae3ec20ff63c6a5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"431389ce41c94c8196890316c75707fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26264cf68fc24d9fb1f2e295c52c0980"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",  # Normal float 4-bit\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\",\n                                             quantization_config=bnb_config,\n                                             token=access_token,\n                                             device_map=\"auto\")\nprint(\"Base Model Has Loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:45:35.034915Z","iopub.execute_input":"2025-05-07T09:45:35.035384Z","iopub.status.idle":"2025-05-07T09:46:32.200449Z","shell.execute_reply.started":"2025-05-07T09:45:35.035364Z","shell.execute_reply":"2025-05-07T09:46:32.199837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f24800ce81468fa1b3d4b6114bbd29"}},"metadata":{}},{"name":"stdout","text":"Base Model Has Loaded\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# LoRA configuration\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\n\n\n# Integrate LoRA\nbase_model = get_peft_model(model, lora_config)\nbase_model.print_trainable_parameters()\n\nprint(\"Model is Loaded\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:46:36.540939Z","iopub.execute_input":"2025-05-07T09:46:36.541660Z","iopub.status.idle":"2025-05-07T09:46:36.649778Z","shell.execute_reply.started":"2025-05-07T09:46:36.541633Z","shell.execute_reply":"2025-05-07T09:46:36.649054Z"}},"outputs":[{"name":"stdout","text":"trainable params: 3,407,872 || all params: 7,251,431,424 || trainable%: 0.0470\nModel is Loaded\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    num_train_epochs=5,\n    learning_rate=2e-4,\n    logging_steps=50,\n    optim=\"adamw_torch\",\n    evaluation_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    report_to=\"none\",       \n    save_strategy=\"epoch\", \n    save_total_limit=2,\n    fp16=True,  \n    deepspeed=None,  \n)\n\n\ntrainer = Trainer(\n    model=base_model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\nprint(\"Traning Starts Here\")\n\nimport shutil\nimport os\n\nsource_ckpt = \"/kaggle/input/checkpoint/transformers/default/1/checkpoint-2000\"\ntarget_ckpt = \"/kaggle/working/checkpoint-2000\"\n\n# Copy the checkpoint directory to a writable location\nif not os.path.exists(target_ckpt):\n    shutil.copytree(source_ckpt, target_ckpt)\n\nfor fname in [\"optimizer.pt\", \"scheduler.pt\"]:\n    fpath = os.path.join(target_ckpt, fname)\n    if os.path.exists(fpath):\n        os.remove(fpath)\n\n#trainer.train()\ntrainer.train(resume_from_checkpoint=target_ckpt)\n\n\n\nmodel_save_path = \"/kaggle/working/saved_model\"\nbase_model.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\n\nrepo_name = \"Fine_tuned_ministral\" \nbase_model.push_to_hub(repo_id=repo_name)\ntokenizer.push_to_hub(repo_id=repo_name)\n!zip -r \"/kaggle/working/fine_tuned_model.zip\" {model_save_path}\n\n\nprint(f\"Model saved and pushed to Hugging Face, and zipped for download as /kaggle/working/{repo_name}_model.zip\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:46:50.482561Z","iopub.execute_input":"2025-05-07T09:46:50.483331Z","iopub.status.idle":"2025-05-07T12:34:05.044109Z","shell.execute_reply.started":"2025-05-07T09:46:50.483305Z","shell.execute_reply":"2025-05-07T12:34:05.043044Z"}},"outputs":[{"name":"stdout","text":"Traning Starts Here\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 2:46:41, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>1.666700</td>\n      <td>1.742844</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57d6e3042b4f4861b18ecf7c2dff3513"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62a9fda6b8734bc18c177e6428cc72c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13571389ce854fb0a87a2a35fb84b281"}},"metadata":{}},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/saved_model/ (stored 0%)\n  adding: kaggle/working/saved_model/adapter_config.json (deflated 51%)\n  adding: kaggle/working/saved_model/README.md (deflated 66%)\n  adding: kaggle/working/saved_model/special_tokens_map.json (deflated 73%)\n  adding: kaggle/working/saved_model/tokenizer_config.json (deflated 95%)\n  adding: kaggle/working/saved_model/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/saved_model/tokenizer.json (deflated 85%)\n  adding: kaggle/working/saved_model/tokenizer.model (deflated 61%)\nModel saved and pushed to Hugging Face, and zipped for download as /kaggle/working/Fine_tuned_ministral_model.zip\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Inference and Output","metadata":{}},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",  # Normal float 4-bit\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\n\nfine_tuned_model = AutoModelForCausalLM.from_pretrained(\"AliHassna/Fine_tuned_ministral\",\n                                             quantization_config=bnb_config,\n                                            device_map=\"auto\"\n                                            )\nfine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"AliHassna/Fine_tuned_ministral\")\n\nprint(\"Fine Tuned Model Has Loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:37:21.653062Z","iopub.execute_input":"2025-05-07T12:37:21.653759Z","iopub.status.idle":"2025-05-07T12:38:26.450396Z","shell.execute_reply.started":"2025-05-07T12:37:21.653717Z","shell.execute_reply":"2025-05-07T12:38:26.449534Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c3c7232aac430ba663fb826b993ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de9e3208a7141cd9bcf14615484ea30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aef219a24314ce190bcaca777ebd371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c81a652053184a29ba4f7012dade5b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e6ad710679470e8969b5e92616a2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a756cc7b408d4f6fa17a85d787e81cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd4bf0cf21084a9bacdd38bba1d8af67"}},"metadata":{}},{"name":"stdout","text":"Fine Tuned Model Has Loaded\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from datasets import load_dataset\nds2 = load_dataset(\"ccdv/arxiv-summarization\", \"section\")[\"train\"]\nds2 = ds2.select(range(5000))\nsplit_ds = ds2.train_test_split(test_size=0.2, seed=42)\n\nval_test_split = split_ds['test'].train_test_split(test_size=0.5, seed=42)\ntrain_dataset = split_ds['train']\nval_dataset = val_test_split['train']\ntest_dataset = val_test_split['test']\n\nprint(\"Dataset Loaded and Splitted Successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:38:30.906722Z","iopub.execute_input":"2025-05-07T12:38:30.907042Z","iopub.status.idle":"2025-05-07T12:38:35.801946Z","shell.execute_reply.started":"2025-05-07T12:38:30.907020Z","shell.execute_reply":"2025-05-07T12:38:35.801158Z"}},"outputs":[{"name":"stdout","text":"Dataset Loaded and Splitted Successfully\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"samples = test_dataset.shuffle(seed=42).select(range(10))\nresults = []\n\nfor sample in samples:\n    input_text = sample['article']\n    ground_truth = sample['abstract']\n\n    # Tokenize input\n    inputs = fine_tuned_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048, padding=\"max_length\")\n    # Generate using fine-tuned model\n    with torch.no_grad():\n        fine_tuned_outputs = fine_tuned_model.generate(\n            **inputs,\n            max_new_tokens=150,\n            do_sample=False,\n            early_stopping = True\n        )\n    fine_tuned_summary = tokenizer.decode(fine_tuned_outputs[0], skip_special_tokens=True)\n\n    # Generate using base model\n    with torch.no_grad():\n        base_outputs = base_model.generate(\n            **inputs,\n            max_new_tokens=150,\n            do_sample=False\n        )\n    base_summary = tokenizer.decode(base_outputs[0], skip_special_tokens=True)\n\n    results.append({\n        \"Input Article\": input_text,\n        \"Ground Truth Abstract\": ground_truth,\n        \"Base Model Summary\": base_summary,\n        \"Fine-tuned Model Summary\": fine_tuned_summary\n    })\n\n# Save results into a JSON or CSV file for easy comparison\nimport pandas as pd\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"summaries_comparison.csv\", index=False)\n\nprint(\"Saved results to summaries_comparison.csv ✅\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:38:41.836061Z","iopub.execute_input":"2025-05-07T12:38:41.836343Z","iopub.status.idle":"2025-05-07T12:44:21.542060Z","shell.execute_reply.started":"2025-05-07T12:38:41.836322Z","shell.execute_reply":"2025-05-07T12:44:21.541350Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Saved results to summaries_comparison.csv ✅\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df.iloc[0]['Fine-tuned Model Summary']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"import evaluate\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nimport bert_score\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Download necessary NLTK packages\nnltk.download('punkt')\n\n# Load evaluation libraries\nrouge = evaluate.load('rouge')\n\n# Prepare lists\nfine_tuned_metrics = []\nbase_model_metrics = []\n\nfor result in results:  # from your earlier results list\n    reference = result[\"Ground Truth Abstract\"]\n    base_summary = result[\"Base Model Summary\"]\n    fine_summary = result[\"Fine-tuned Model Summary\"]\n\n    # ROUGE (using evaluate library)\n    rouge_base = rouge.compute(predictions=[base_summary], references=[reference])\n    rouge_fine = rouge.compute(predictions=[fine_summary], references=[reference])\n\n    # BLEU (using NLTK, at sentence level)\n    reference_tokens = nltk.word_tokenize(reference)\n    base_tokens = nltk.word_tokenize(base_summary)\n    fine_tokens = nltk.word_tokenize(fine_summary)\n\n    bleu_base = sentence_bleu([reference_tokens], base_tokens)\n    bleu_fine = sentence_bleu([reference_tokens], fine_tokens)\n\n    # BERTScore (semantic similarity)\n    bert_base = bert_score.score([base_summary], [reference], lang=\"en\", verbose=False)\n    bert_fine = bert_score.score([fine_summary], [reference], lang=\"en\", verbose=False)\n\n    fine_tuned_metrics.append({\n        \"rouge1\": rouge_fine[\"rouge1\"],\n        \"rougeL\": rouge_fine[\"rougeL\"],\n        \"bleu\": bleu_fine,\n        \"bertscore\": bert_fine[2].mean().item()  # F1 score\n    })\n\n    base_model_metrics.append({\n        \"rouge1\": rouge_base[\"rouge1\"],\n        \"rougeL\": rouge_base[\"rougeL\"],\n        \"bleu\": bleu_base,\n        \"bertscore\": bert_base[2].mean().item()\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:44:27.323689Z","iopub.execute_input":"2025-05-07T12:44:27.324555Z","iopub.status.idle":"2025-05-07T12:45:16.318716Z","shell.execute_reply.started":"2025-05-07T12:44:27.324526Z","shell.execute_reply":"2025-05-07T12:45:16.317742Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4f0435715fb4bb381cbd848ad7f0629"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccbab445540b49ac9046275ae497036f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c738e397fa4b9f94d6d43b68343d1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3dabf98c1b4e26bf57739b55b17caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eda902d9ecf4dfd809f3a7363fe5ffe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac99a75101114f38b3720124a6b3836e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5cc315ef264f9f9995bdaee78f1d4e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\n\n# Convert to DataFrames\nfine_df = pd.DataFrame(fine_tuned_metrics)\nbase_df = pd.DataFrame(base_model_metrics)\n\n# Calculate means\nfine_means = fine_df.mean()\nbase_means = base_df.mean()\n\n# Plot\nmetrics = [\"rouge1\", \"rougeL\", \"bleu\", \"bertscore\"]\n\nx = range(len(metrics))\nwidth = 0.35\n\nplt.bar(x, fine_means[metrics], width=width, label=\"Fine-tuned Model\")\nplt.bar([i + width for i in x], base_means[metrics], width=width, label=\"Base Model\")\n\nplt.xticks([i + width/2 for i in x], metrics)\nplt.ylabel(\"Score\")\nplt.title(\"Model Evaluation Metrics\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:46:10.843195Z","iopub.execute_input":"2025-05-07T12:46:10.843537Z","iopub.status.idle":"2025-05-07T12:46:11.103342Z","shell.execute_reply.started":"2025-05-07T12:46:10.843516Z","shell.execute_reply":"2025-05-07T12:46:11.102590Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## LLM as a Judge","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport re\nimport time\nfrom together import Together\n\nclient = Together(api_key=together_api_key)\n\nsamples = pd.read_csv(\"/kaggle/working/summaries_comparison.csv\")\n\n\nevaluations = []\n\nfor idx, row in samples.iterrows():\n    article = row[\"Input Article\"][:3000]\n    summary = row[\"Fine-tuned Model Summary\"]\n\n    prompt = f\"\"\"\nYou are a helpful scientific writing evaluator. Assess the quality of a machine-generated summary of a scientific article based on the following:\n\n1. **Fluency** (1-5): Is the summary readable and grammatically correct?\n2. **Factuality** (1-5): Are the claims accurate and reflective of the original article?\n3. **Coverage** (1-5): Does the summary include the main problem, method, and key findings?\n\nProvide a score (1 to 5) and one-sentence justification for each.\n\n### Article:\n{article}\n\n### Generated Summary:\n{summary}\n\n### Evaluation:\nFluency:\nFactuality:\nCoverage:\n\"\"\"\n\n    response = client.chat.completions.create(\n        model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.3,\n    )\n\n    evaluation = response.choices[0].message.content.strip()\n    evaluations.append({\n        \"Input Article\": article,\n        \"Generated Summary\": summary,\n        \"Evaluation\": evaluation\n    })\n    time.sleep(60)\n\n# Save raw evaluation output\neval_df = pd.DataFrame(evaluations)\neval_df.to_csv(\"llm_judge_fp8_evaluations.csv\", index=False)\nprint(\"✅ Saved evaluation to llm_judge_fp8_evaluations.csv\")\n\n# Optional: parse numeric scores and calculate averages\nfluency_scores, factuality_scores, coverage_scores = [], [], []\n\nfor eval in eval_df[\"Evaluation\"]:\n    flu = re.search(r'Fluency.*?(\\d)', eval)\n    fac = re.search(r'Factuality.*?(\\d)', eval)\n    cov = re.search(r'Coverage.*?(\\d)', eval)\n    if flu and fac and cov:\n        fluency_scores.append(int(flu.group(1)))\n        factuality_scores.append(int(fac.group(1)))\n        coverage_scores.append(int(cov.group(1)))\n\nprint(f\"\\n🔎 Average Fluency: {sum(fluency_scores)/len(fluency_scores):.2f}\")\nprint(f\"🔎 Average Factuality: {sum(factuality_scores)/len(factuality_scores):.2f}\")\nprint(f\"🔎 Average Coverage: {sum(coverage_scores)/len(coverage_scores):.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:51:03.506555Z","iopub.execute_input":"2025-05-07T12:51:03.506909Z","iopub.status.idle":"2025-05-07T12:52:32.515483Z","shell.execute_reply.started":"2025-05-07T12:51:03.506885Z","shell.execute_reply":"2025-05-07T12:52:32.514385Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2801470687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \"\"\"\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         ).model_dump(exclude_none=True)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         response, _, _ = requestor.request(\n\u001b[0m\u001b[1;32m    142\u001b[0m             options=TogetherRequest(\n\u001b[1;32m    143\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             return (\n\u001b[0;32m--> 635\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    636\u001b[0m                     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/together/abstract/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Handle streaming errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_error_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8. The maximum rate limit for this model is 0.6 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}"],"ename":"RateLimitError","evalue":"Error code: 429 - {\"message\": \"You have reached the rate limit specific to this model meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8. The maximum rate limit for this model is 0.6 queries and 60000 tokens per minute. This limit differs from the general rate limits published at Together AI rate limits documentation (https://docs.together.ai/docs/rate-limits). For inquiries about increasing your model-specific rate limit, please contact our sales team (https://www.together.ai/forms/contact-sales)\", \"type_\": \"model_rate_limit\"}","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}